# data_harvesters.py
# –í–µ—Ä—Å–∏—è: 2.0 (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –∏ —Ä–∞–±–æ—Ç—ã –ø–æ —Å–ø–∏—Å–∫—É)

import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
import requests
from datetime import datetime, timedelta
import logging
import numpy as np

# =============================================================================
# --- –ë–õ–û–ö 1: –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï ---
# =============================================================================
CREDS_FILE = 'credentials.json'
SPREADSHEET_URL = "https://docs.google.com/spreadsheets/d/1qBYS_DhGNsTo-Dnph3g_H27aHQOoY0EOcmCIKarb7Zc/"
SCOPE = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive.file']

def get_gsheets_client(creds_file=CREDS_FILE, scope=SCOPE) -> gspread.Client | None:
    """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Google Sheets –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç –∫–ª–∏–µ–Ω—Ç–∞."""
    try:
        creds = Credentials.from_service_account_file(creds_file, scopes=scope)
        client = gspread.authorize(creds)
        logging.info("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ Google Sheets –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.")
        return client
    except FileNotFoundError:
        logging.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –§–∞–π–ª credentials.json –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ Google: {e}")
        return None

# =============================================================================
# --- –ë–õ–û–ö 2: –§–£–ù–ö–¶–ò–ò-–°–ë–û–†–©–ò–ö–ò ---
# =============================================================================
def get_moex_history(ticker: str, start_date: str, market: str, board: str, interval: int) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Å–≤–µ—á–µ–π (OHLCV) –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ —Å MOEX —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º.
    interval: 1, 10, 30 (–º–∏–Ω—É—Ç—ã), 60 (—á–∞—Å), 24 (–¥–µ–Ω—å), 7 (–Ω–µ–¥–µ–ª—è), 31 (–º–µ—Å—è—Ü), 4 (–∫–≤–∞—Ä—Ç–∞–ª).
    """
    logging.info(f"  - –ó–∞–ø—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {ticker} ({market}/{board}) —Å –¥–∞—Ç—ã {start_date}, –∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval}...")
    url = f"https://iss.moex.com/iss/history/engines/stock/markets/{market}/boards/{board}/securities/{ticker}.json?from={start_date}&interval={interval}&iss.meta=off"
    
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json().get('history', {})
        if not data.get('data'):
            logging.warning(f"    - ‚ö†Ô∏è –î–ª—è {ticker} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞—Å—å –∏—Å—Ç–æ—Ä–∏—è (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval}). –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç —Ç–æ—Ä–≥–æ–≤.")
            return pd.DataFrame()

        cols = data['columns']
        df = pd.DataFrame(data['data'], columns=cols)
        required_cols = ['TRADEDATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME']
        df = df[required_cols]
        df.rename(columns={'TRADEDATE': 'Date'}, inplace=True)
        return df
    except requests.exceptions.RequestException as e:
        logging.error(f"    - ‚ùå –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {ticker}: {e}")
        return pd.DataFrame()
    except Exception as e:
        logging.error(f"    - ‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {ticker}: {e}")
        return pd.DataFrame()

# =============================================================================
# --- –ë–õ–û–ö 3: –ì–õ–ê–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
# =============================================================================
def main_history_updater(interval: int = 24, tickers_to_process: list[str] | None = None):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    """
    timeframe_map = {24: 'D1', 60: 'H1', 30: 'm30', 10: 'm10', 1: 'm1'}
    timeframe_label = timeframe_map.get(interval, f'm{interval}')

    logging.info("\n" + "="*50)
    logging.info(f"--- ‚ú® –ê–°–£–ü –ò–ò: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ò—Å—Ç–æ—Ä–∏–∏ v2.0 (–ò–Ω—Ç–µ—Ä–≤–∞–ª: {timeframe_label}) ‚ú® ---")
    logging.info("="*50)

    client = get_gsheets_client()
    if not client: return

    try:
        spreadsheet = client.open_by_url(SPREADSHEET_URL)
        holdings_sheet = spreadsheet.worksheet('Holdings')
        history_sheet = spreadsheet.worksheet('History_OHLCV')
    except Exception as e:
        logging.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –∏–ª–∏ –ª–∏—Å—Ç—ã. {e}")
        return

    holdings_df = pd.DataFrame(holdings_sheet.get_all_records())
    history_records = history_sheet.get_all_records()
    
    history_df = pd.DataFrame(history_records[1:], columns=history_records[0]) if len(history_records) > 1 else pd.DataFrame()
    if not history_df.empty:
        history_df_filtered = history_df[history_df['Timeframe'] == timeframe_label]
    else:
        history_df_filtered = pd.DataFrame()

    if tickers_to_process is None:
        logging.info("–†–µ–∂–∏–º 'Daily': –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –∞–∫—Ç–∏–≤—ã –∏–∑ –ª–∏—Å—Ç–∞ Holdings.")
        tickers_to_iterate = holdings_df[holdings_df['Type'].isin(['Stock_MOEX', 'Bond_MOEX'])]['Ticker'].tolist()
    else:
        logging.info(f"–†–µ–∂–∏–º 'Intraday': –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Ç–∏–∫–µ—Ä—ã –∏–∑ '–≥–æ—Ä—è—á–µ–≥–æ —Å–ø–∏—Å–∫–∞' ({len(tickers_to_process)} —à—Ç).")
        tickers_to_iterate = tickers_to_process

    new_history_rows = []

    for ticker in tickers_to_iterate:
        asset_info = holdings_df[holdings_df['Ticker'] == ticker]
        if asset_info.empty:
            logging.warning(f"–¢–∏–∫–µ—Ä '{ticker}' –∏–∑ '–≥–æ—Ä—è—á–µ–≥–æ —Å–ø–∏—Å–∫–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Holdings. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
            continue
        
        asset_type = asset_info['Type'].iloc[0]
        market, board = ('shares', 'TQBR') if asset_type == 'Stock_MOEX' else ('bonds', 'TQOB')

        last_date_str = None
        if not history_df_filtered.empty and 'Ticker' in history_df_filtered.columns:
            ticker_dates = history_df_filtered[history_df_filtered['Ticker'] == ticker]['Date']
            if not ticker_dates.empty:
                last_date_str = ticker_dates.max()

        start_date = (datetime.strptime(last_date_str, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d') if pd.notna(last_date_str) else (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
        
        ticker_history_df = get_moex_history(ticker, start_date, market, board, interval)

        if not ticker_history_df.empty:
            ticker_history_df.replace([np.inf, -np.inf], np.nan, inplace=True)
            ticker_history_df.fillna('', inplace=True)

            for _, row in ticker_history_df.iterrows():
                new_history_rows.append([row['Date'], timeframe_label, ticker, row['OPEN'], row['HIGH'], row['LOW'], row['CLOSE'], row['VOLUME']])

    if new_history_rows:
        logging.info(f"\nüîÑ –ù–∞–π–¥–µ–Ω–æ {len(new_history_rows)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è {timeframe_label}. –î–æ–±–∞–≤–ª—è—é –≤ 'History_OHLCV'...")
        history_sheet.append_rows(new_history_rows, value_input_option='USER_ENTERED')
        logging.info(f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è —É—Å–ø–µ—à–Ω–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∞.")
    else:
        logging.info(f"‚úÖ –ù–æ–≤—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {timeframe_label} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

    logging.info("--- üèÅ –†–ê–ë–û–¢–ê –û–ë–ù–û–í–ò–¢–ï–õ–Ø –ò–°–¢–û–†–ò–ò –ó–ê–í–ï–†–®–ï–ù–ê üèÅ ---")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    main_history_updater(interval=24)